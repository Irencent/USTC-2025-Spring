\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\@writefile{toc}{\contentsline {section}{\numberline {1}NLP预训练技术的发展与GPT的突破}{2}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}从词向量到上下文建模：预训练的发展脉络}{2}{subsection.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces 预训练语言模型的发展路径\relax }}{3}{figure.caption.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Word2Vec：静态词嵌入}{3}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{ELMo：上下文感知的动态词向量}{3}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}GPT的提出与创新}{3}{subsection.1.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces GPT、BERT、ELMo、ULMFiT 模型比较\relax }}{4}{table.caption.5}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:pretrained_models_comparison}{{1}{4}{GPT、BERT、ELMo、ULMFiT 模型比较\relax }{table.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}GPT在2018年的技术突破点}{4}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}模型架构}{5}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}预训练语料 BooksCorpus 的选择与优势}{5}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}位置编码}{6}{subsection.2.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces 位置编码方式的对比\relax }}{6}{table.caption.6}\protected@file@percent }
\newlabel{tab:positional_encoding_comparison}{{2}{6}{位置编码方式的对比\relax }{table.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}激活函数与归一化策略}{6}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}残差连接的作用}{7}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}多层 Transformer Decoder 的结构简析}{7}{subsection.2.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces GPT-1 的 Transformer Decoder 结构\relax }}{8}{figure.caption.7}\protected@file@percent }
\newlabel{fig:transformer_decoder_structure}{{2}{8}{GPT-1 的 Transformer Decoder 结构\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}多头注意力参数}{8}{subsection.2.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces 多头注意力机制示意图\relax }}{9}{figure.caption.8}\protected@file@percent }
\newlabel{fig:multihead_attention}{{3}{9}{多头注意力机制示意图\relax }{figure.caption.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces 多头注意力层参数量分析\relax }}{9}{table.caption.9}\protected@file@percent }
\newlabel{tab:multihead_attention_params}{{3}{9}{多头注意力层参数量分析\relax }{table.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}模型参数总量与计算复杂度}{10}{subsection.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}小结}{10}{subsection.2.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}训练策略与任务统一格式设计}{11}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}语言建模目标函数简析}{11}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}任务统一：Token流视角的建模策略}{11}{subsection.3.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces 不同任务如何转化为统一 token 序列进行微调\relax }}{12}{table.caption.10}\protected@file@percent }
\newlabel{tab:task_unification}{{4}{12}{不同任务如何转化为统一 token 序列进行微调\relax }{table.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces 任务统一的 token 流示图\relax }}{12}{figure.caption.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}GPT 学习率预热曲线}{13}{subsection.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces GPT学习率预热曲线\relax }}{13}{figure.caption.12}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}实验结果与分析}{14}{section.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces 实验结果图\relax }}{14}{figure.caption.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}自然语言推理}{14}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}问答与常识推理}{14}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}语义相似度与分类任务}{15}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}综合GLUE得分分析}{15}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}方法局限与理论改进}{15}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}现有方法的不足}{15}{subsection.5.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces GPT-1 方法的不足\relax }}{16}{table.caption.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}结构性改进（Architecture-Level Improvements）}{16}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}双向建模（Bidirectional Modeling）}{16}{subsubsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}稀疏注意力（Sparse Attention）}{16}{subsubsection.5.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}预训练目标与学习方法改进}{17}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}统一预训练目标（Unified Objectives）}{17}{subsubsection.5.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}优化与训练效率提升（Efficiency-Oriented Enhancements）}{17}{subsection.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.1}优化器与调度策略}{17}{subsubsection.5.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.2}参数压缩与低秩建模}{17}{subsubsection.5.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}GPT-1 的影响与后续演进}{17}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}GPT-2：扩大模型规模，推进纯生成方向}{17}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}GPT-3：few-shot 能力的极限扩展}{18}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}InstructGPT 与 ChatGPT：对齐优化与 RLHF 的引入}{18}{subsection.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Appendices}{20}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{附录 \numberline {A.1}Transformer Decoder 的数学推导}{20}{appendix.1.A}\protected@file@percent }
\newlabel{appendix:transformer_math}{{A.1}{20}{Transformer Decoder 的数学推导}{appendix.1.A}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.1}输入嵌入（Embedding + Position Encoding）}{20}{subsection.1.A.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.2}Transformer Block（第 $l$ 层）}{20}{subsection.1.A.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Masked Multi-Head Self-Attention}{20}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{前馈网络（Feed-Forward Network）}{20}{section*.17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.3}输出预测}{21}{subsection.1.A.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{附录 \numberline {A.2}最大似然估计的收敛性与优化性分析}{21}{appendix.1.B}\protected@file@percent }
\newlabel{appendix:mle_proof}{{A.2}{21}{最大似然估计的收敛性与优化性分析}{appendix.1.B}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.1}最大似然估计的收敛性（Consistency of MLE）}{21}{subsection.1.B.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.2}训练过程的优化收敛性}{21}{subsection.1.B.2}\protected@file@percent }
\gdef \@abspage@last{22}
